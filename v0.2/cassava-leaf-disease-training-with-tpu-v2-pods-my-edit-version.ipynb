{"cells":[{"metadata":{"papermill":{"duration":0.034254,"end_time":"2020-10-10T21:25:09.791326","exception":false,"start_time":"2020-10-10T21:25:09.757072","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<center><img src=\"https://raw.githubusercontent.com/dimitreOliveira/MachineLearning/master/Kaggle/Cassava%20Leaf%20Disease%20Classification/banner.png\" width=\"1000\"></center>\n<br>\n<center><h1>Cassava Leaf Disease - Training with TPU v2 Pods</h1></center>\n<br>\n\n#### This is based on my previous work [Cassava Leaf Disease - TPU Tensorflow - Training](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-tpu-tensorflow-training)\n\n\n- [Inference notebook](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-tpu-v2-pods-inference)\n- Dataset source `center cropped` [512x512](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-50-tfrecords-center-512x512) - `divided by classes` [512x512](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-50-tfrecords-classes-512x512)\n- Dataset source `external data` `center cropped` [512x512](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-50-tfrecords-external-512x512) - `divided by classes` [512x512](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-ext-50-tfrec-classes-512x512)\n- Dataset source [discussion thread](https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198744)\n- Dataset [creation source](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-stratified-tfrecords-256x256)"},{"metadata":{},"cell_type":"markdown","source":"### What is a TPU pod?\n\n> To accelerate the largest-scale machine learning (ML) applications deployed today and enable rapid development of the ML applications of tomorrow, Google created custom silicon chips called Tensor Processing Units ([TPUs](https://cloud.google.com/tpu/docs/tpus)). When assembled into multi-rack ML supercomputers called Cloud TPU Pods.\n\n\n<center><img src=\"https://miro.medium.com/max/890/1*16HkeV33jzWruFoVYokVlQ.png\" width=\"800\"></center>\n<br>\n\n\n### What’s in a Cloud TPU Pod\n> A single Cloud TPU Pod can include more than 1,000 individual TPU chips which are connected by an ultra-fast, two-dimensional toroidal mesh network, as illustrated below. The TPU software stack uses this mesh network to enable many racks of machines to be programmed as a single, giant ML supercomputer via a variety of flexible, high-level APIs.\n\n\n\n\n> References:\n- [Use TPUs](https://www.tensorflow.org/guide/tpu)\n- [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)\n- [Custom training with tf.distribute.Strategy](https://www.tensorflow.org/tutorials/distribute/custom_training)\n- [Cloud TPU](https://cloud.google.com/tpu)\n- [Google’s scalable supercomputers for machine learning, Cloud TPU Pods, are now publicly available in beta](https://cloud.google.com/blog/products/ai-machine-learning/googles-scalable-supercomputers-for-machine-learning-cloud-tpu-pods-are-now-publicly-available-in-beta)"},{"metadata":{},"cell_type":"markdown","source":"Improvements\n - `Custom training loop`: Using a custom training loop greatly improves the training time and resource usage.\n - `Maximize MXU and minimize Idle time`: I have made a few adjustments to the Tensorflow pipeline to improve performance.\n\nExperiments\n - Small improvements using external data (2019 competition).\n - Small improvements from using `CCE label smoothing`.\n - Small improvements from using `CutOut`.\n - Small improvements from `oversmapling` classes `0`, `1`, `2` and `4`.\n - Small improvements from keeping `batch normalization` layers frozen.\n - No relevant improvements from using `class weights`.\n - No relevant improvements from using `MixUp`.\n - No relevant improvements from using different backbones.\n - Worse performance by using different image resolution even the default `EfficientNet` input size.\n - Changing `Sparse CCE` to `CCE` has no impact, as expected.\n - Was not able to make progressive unfreezing work.\n - Changing the `learning rate` batch wise seems more efficent than epoch wise, specially for the warm up phase."},{"metadata":{"papermill":{"duration":0.033986,"end_time":"2020-10-10T21:25:09.858267","exception":false,"start_time":"2020-10-10T21:25:09.824281","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Dependencies"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install --quiet efficientnet","execution_count":24,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-10-10T21:25:09.94291Z","iopub.status.busy":"2020-10-10T21:25:09.94211Z","iopub.status.idle":"2020-10-10T21:25:26.556399Z","shell.execute_reply":"2020-10-10T21:25:26.555607Z"},"papermill":{"duration":16.665386,"end_time":"2020-10-10T21:25:26.556557","exception":false,"start_time":"2020-10-10T21:25:09.891171","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import math, os, re, warnings, random, time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers, Sequential, losses, metrics, Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport efficientnet.tfkeras as efn\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"metadata":{"papermill":{"duration":0.03302,"end_time":"2020-10-10T21:25:26.623975","exception":false,"start_time":"2020-10-10T21:25:26.590955","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Hardware configuration\n\nNote that we have `32` cores, this is because the `TPU v2 Pod` have more cores than a single `TPU v3` which has `8` cores."},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T21:25:26.705656Z","iopub.status.busy":"2020-10-10T21:25:26.704813Z","iopub.status.idle":"2020-10-10T21:25:31.882446Z","shell.execute_reply":"2020-10-10T21:25:31.881768Z"},"papermill":{"duration":5.225184,"end_time":"2020-10-10T21:25:31.882571","exception":false,"start_time":"2020-10-10T21:25:26.657387","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","execution_count":27,"outputs":[{"output_type":"stream","text":"Running on TPU grpc://10.0.0.2:8470\nREPLICAS: 8\n","name":"stdout"}]},{"metadata":{"papermill":{"duration":0.034123,"end_time":"2020-10-10T21:25:31.952284","exception":false,"start_time":"2020-10-10T21:25:31.918161","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Model parameters"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-10T21:25:32.028802Z","iopub.status.busy":"2020-10-10T21:25:32.027887Z","iopub.status.idle":"2020-10-10T21:25:32.031045Z","shell.execute_reply":"2020-10-10T21:25:32.030416Z"},"papermill":{"duration":0.044623,"end_time":"2020-10-10T21:25:32.031164","exception":false,"start_time":"2020-10-10T21:25:31.986541","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8 * REPLICAS\nAUG_BATCH = 2 * BATCH_SIZE\nLEARNING_RATE = 1e-5 * REPLICAS\nEPOCHS = 10\nHEIGHT = 512\nWIDTH = 512\nHEIGHT_RS = 512\nWIDTH_RS = 512\nCHANNELS = 3\nN_CLASSES = 5\nN_FOLDS = 5\nFOLDS_USED = 5\nES_PATIENCE = 5\nIMAGE_SIZE = [512, 512]\nclasses = ['0', '1', '2', '3', '4']  ","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-10T21:25:32.118263Z","iopub.status.busy":"2020-10-10T21:25:32.115381Z","iopub.status.idle":"2020-10-10T21:25:32.677665Z","shell.execute_reply":"2020-10-10T21:25:32.677043Z"},"papermill":{"duration":0.61129,"end_time":"2020-10-10T21:25:32.677805","exception":false,"start_time":"2020-10-10T21:25:32.066515","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def count_data_items(filenames):\n    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n\ndatabase_base_path = '/kaggle/input/cassava-leaf-disease-classification/'\ntrain = pd.read_csv(f'{database_base_path}train.csv')\nprint(f'Train samples: {len(train)}')\n\n# GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') # Original dataset\nGCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-50-tfrecords-center-{HEIGHT}x{WIDTH}') # Center croped and resized (50 TFRecord)\nGCS_PATH_EXT = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-50-tfrecords-external-{HEIGHT}x{WIDTH}') # Center croped and resized (50 TFRecord) (External)\nGCS_PATH_CLASSES = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-50-tfrecords-classes-{HEIGHT}x{WIDTH}') # Center croped and resized (50 TFRecord) by classes\nGCS_PATH_EXT_CLASSES = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-ext-50-tfrec-classes-{HEIGHT}x{WIDTH}') # Center croped and resized (50 TFRecord) (External) by classes\n\n# FILENAMES_COMP = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/*.tfrec') # Original TFRecords\nFILENAMES_COMP = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\nFILENAMES_2019 = tf.io.gfile.glob(GCS_PATH_EXT + '/*.tfrec')\n\nFILENAMES_COMP_CBB = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBB*.tfrec')\nFILENAMES_COMP_CBSD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBSD*.tfrec')\nFILENAMES_COMP_CGM = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CGM*.tfrec')\nFILENAMES_COMP_CMD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CMD*.tfrec')\nFILENAMES_COMP_Healthy = tf.io.gfile.glob(GCS_PATH_CLASSES + '/Healthy*.tfrec')\n\nFILENAMES_2019_CBB = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBB*.tfrec')\nFILENAMES_2019_CBSD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBSD*.tfrec')\nFILENAMES_2019_CGM = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CGM*.tfrec')\nFILENAMES_2019_CMD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CMD*.tfrec')\nFILENAMES_2019_Healthy = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/Healthy*.tfrec')\n\n\nTRAINING_FILENAMES = (FILENAMES_COMP + \n                      FILENAMES_2019 + \n                      (2 * FILENAMES_COMP_CBB) + \n                      (2 * FILENAMES_2019_CBB) + \n                      (2 * FILENAMES_COMP_CBSD) + \n                      (2 * FILENAMES_2019_CBSD) + \n                      (2 * FILENAMES_COMP_CGM) + \n                      (2 * FILENAMES_2019_CGM) + \n                      (2 * FILENAMES_COMP_Healthy) + \n                      (2 * FILENAMES_2019_Healthy))\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n\nprint(f'GCS: train images: {NUM_TRAINING_IMAGES}')\ndisplay(train.head())\n\nCLASSES = ['Cassava Bacterial Blight', \n           'Cassava Brown Streak Disease', \n           'Cassava Green Mottle', \n           'Cassava Mosaic Disease', \n           'Healthy']","execution_count":29,"outputs":[{"output_type":"stream","text":"Train samples: 21397\nGCS: train images: 48081\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"         image_id  label\n0  1000015157.jpg      0\n1  1000201771.jpg      3\n2   100042118.jpg      1\n3  1000723321.jpg      1\n4  1000812911.jpg      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000015157.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000201771.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100042118.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000723321.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000812911.jpg</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#need to one hot encode images so we can blend their labels like above\ndef onehot(image,label):\n    CLASSES = len(classes)\n    return image,tf.one_hot(label,CLASSES)\n\ndef mixup(image, label, PROBABILITY = 1.0, DIM = IMAGE_SIZE[0]):\n    CLASSES = len(classes)\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        a = tf.random.uniform([],0,1)*P\n\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image2,label2","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cutmix(image, label, PROBABILITY = 1.0, DIM = IMAGE_SIZE[0]):\n\n    CLASSES = len(classes)\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        b = tf.random.uniform([],0,1)\n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n        \n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image2,label2","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create function to apply both cutmix and mixup\ndef cut_and_mix(image, label, DIM = IMAGE_SIZE[0]):\n    CLASSES = len(classes)\n    \n    #define how often we want to do activate cutmix or mixup\n    SWITCH = 1/2\n    \n    #define how often we want cutmix or mixup to activate when switch is active\n    CUTMIX_PROB = 2/3\n    MIXUP_PROB = 2/3\n    \n    #apply cutmix and mixup\n    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n    image3, label3 = mixup(image, label, MIXUP_PROB)\n    imgs = []; labs = []\n    \n    for j in range(BATCH_SIZE):\n        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n        labs.append(P*label2[j,]+(1-P)*label3[j,])\n        \n    #must explicitly reshape so TPU complier knows output shape\n    image4 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n    label4 = tf.reshape(tf.stack(labs),(BATCH_SIZE,CLASSES))\n    return image4,label4","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):\n    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    # Shear\n    if p_shear > .2:\n        if p_shear > .6:\n            image = transform_shear(image, HEIGHT, shear=20.)\n        else:\n            image = transform_shear(image, HEIGHT, shear=-20.)\n            \n    # Rotation\n    if p_rotation > .2:\n        if p_rotation > .6:\n            image = transform_rotation(image, HEIGHT, rotation=45.)\n        else:\n            image = transform_rotation(image, HEIGHT, rotation=-45.)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270º\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180º\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90º\n        \n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    # Crops\n    if p_crop > .6:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.5)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.6)\n        elif p_crop > .7:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.8)\n    elif p_crop > .3:\n        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n            \n    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n\n    if p_cutout > .5:\n        image = data_augment_cutout(image)\n        \n    return image, label","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Auxiliary functions"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\ndef transform_rotation(image, height, rotation):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated\n    DIM = height\n    XDIM = DIM%2 #fix for size 331\n    \n    rotation = rotation * tf.random.uniform([1],dtype='float32')\n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3])\n\ndef transform_shear(image, height, shear):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly sheared\n    DIM = height\n    XDIM = DIM%2 #fix for size 331\n    \n    shear = shear * tf.random.uniform([1],dtype='float32')\n    shear = math.pi * shear / 180.\n        \n    # SHEAR MATRIX\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3])\n\n# CutOut\ndef data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    if p_cutout > .85: # 10~15 cut outs\n        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    elif p_cutout > .6: # 5~10 cut outs\n        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    elif p_cutout > .25: # 2~5 cut outs\n        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    else: # 1 cut out\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n\n    return image\n\ndef random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n    assert height > min_mask_size[0]\n    assert width > min_mask_size[1]\n    assert height > max_mask_size[0]\n    assert width > max_mask_size[1]\n\n    for i in range(k):\n      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n\n      pad_h = height - mask_height\n      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n      pad_bottom = pad_h - pad_top\n\n      pad_w = width - mask_width\n      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n      pad_right = pad_w - pad_left\n\n      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n\n      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n\n    return image","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-10T21:25:32.781506Z","iopub.status.busy":"2020-10-10T21:25:32.777062Z","iopub.status.idle":"2020-10-10T21:25:32.784982Z","shell.execute_reply":"2020-10-10T21:25:32.78432Z"},"papermill":{"duration":0.072304,"end_time":"2020-10-10T21:25:32.785102","exception":false,"start_time":"2020-10-10T21:25:32.712798","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Datasets utility functions\ndef decode_image(image_data):\n    \"\"\"\n        Decode a JPEG-encoded image to a uint8 tensor.\n    \"\"\"\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    return image\n\ndef scale_image(image, label):\n    \"\"\"\n        Cast tensor to float and normalizes (range between 0 and 1).\n    \"\"\"\n    image = tf.cast(image, tf.float32)\n    image /= 255.0\n    return image, label\n\ndef prepare_image(image, label):\n    \"\"\"\n        Resize and reshape images to the expected size.\n    \"\"\"\n    image = tf.image.resize(image, [HEIGHT_RS, WIDTH_RS])\n    image = tf.reshape(image, [HEIGHT_RS, WIDTH_RS, 3])\n    return image, label","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-10T21:25:32.781506Z","iopub.status.busy":"2020-10-10T21:25:32.777062Z","iopub.status.idle":"2020-10-10T21:25:32.784982Z","shell.execute_reply":"2020-10-10T21:25:32.78432Z"},"papermill":{"duration":0.072304,"end_time":"2020-10-10T21:25:32.785102","exception":false,"start_time":"2020-10-10T21:25:32.712798","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def read_tfrecord(example, labeled=True):\n    \"\"\"\n        1. Parse data based on the 'TFREC_FORMAT' map.\n        2. Decode image.\n        3. If 'labeled' returns (image, label) if not (image, name).\n    \"\"\"\n    if labeled:\n        TFREC_FORMAT = {\n            'image': tf.io.FixedLenFeature([], tf.string), \n            'target': tf.io.FixedLenFeature([], tf.int64), \n        }\n    else:\n        TFREC_FORMAT = {\n            'image': tf.io.FixedLenFeature([], tf.string), \n            'image_name': tf.io.FixedLenFeature([], tf.string), \n        }\n    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n    image = decode_image(example['image'])\n    if labeled:\n        label_or_name = tf.cast(example['target'], tf.int32)\n        # One-Hot Encoding needed to use \"categorical_crossentropy\" loss\n        label_or_name = tf.one_hot(tf.cast(label_or_name, tf.int32), N_CLASSES)\n    else:\n        label_or_name = example['image_name']\n    return image, label_or_name","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-10T21:25:32.781506Z","iopub.status.busy":"2020-10-10T21:25:32.777062Z","iopub.status.idle":"2020-10-10T21:25:32.784982Z","shell.execute_reply":"2020-10-10T21:25:32.78432Z"},"papermill":{"duration":0.072304,"end_time":"2020-10-10T21:25:32.785102","exception":false,"start_time":"2020-10-10T21:25:32.712798","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, \n                cached=False, augment=False, mixup=False):\n    \"\"\"\n        Return a Tensorflow dataset ready for training or inference.\n    \"\"\"\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n        dataset = tf.data.Dataset.list_files(FILENAMES)\n        dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\n    else:\n        dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\n        \n    dataset = dataset.with_options(ignore_order)\n    \n    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n    \n    if augment:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n        \n    dataset = dataset.map(scale_image, num_parallel_calls=AUTO)\n    dataset = dataset.map(prepare_image, num_parallel_calls=AUTO)\n    \n    if not ordered:\n        dataset = dataset.shuffle(2048)\n    if repeated:\n        dataset = dataset.repeat()\n    \n    if mixup:\n        #ds = ds.map(data_augment, num_parallel_calls = AUTO)\n        \n        #need to batch to use CutMix/mixup\n        dataset = dataset.batch(AUG_BATCH)\n        dataset = dataset.map(cut_and_mix, num_parallel_calls = AUTO)\n        \n        #now unbatch and shuffle before re-batching\n        dataset = dataset.unbatch()\n        dataset = dataset.shuffle(2048)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    \n    if cached:\n        dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-10T21:25:32.781506Z","iopub.status.busy":"2020-10-10T21:25:32.777062Z","iopub.status.idle":"2020-10-10T21:25:32.784982Z","shell.execute_reply":"2020-10-10T21:25:32.78432Z"},"papermill":{"duration":0.072304,"end_time":"2020-10-10T21:25:32.785102","exception":false,"start_time":"2020-10-10T21:25:32.712798","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def unfreeze_model(model):\n    # Unfreeze layers while leaving BatchNorm layers frozen\n    for layer in model.layers:\n        if not isinstance(layer, L.BatchNormalization):\n            layer.trainable = True\n        else:\n            layer.trainable = False\n                \ndef unfreeze_block(model, block_name=None, n_top=3):\n    # Unfreeze layers while leaving BatchNorm layers frozen\n    for layer in model.layers[:-n_top]:\n        if isinstance(layer, L.BatchNormalization):\n            layer.trainable = False\n        else:\n            if block_name and (block_name in layer.name):\n                layer.trainable = True","execution_count":38,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T21:25:32.896825Z","iopub.status.busy":"2020-10-10T21:25:32.886455Z","iopub.status.idle":"2020-10-10T21:25:32.900548Z","shell.execute_reply":"2020-10-10T21:25:32.899792Z"},"papermill":{"duration":0.08061,"end_time":"2020-10-10T21:25:32.900668","exception":false,"start_time":"2020-10-10T21:25:32.820058","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Visualization utility functions\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', \n                  fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n\ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    labels = np.argmax(labels, axis=-1)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n    \n# Visualize model predictions\ndef dataset_to_numpy_util(dataset, N):\n    dataset = dataset.unbatch().batch(N)\n    for images, labels in dataset:\n        numpy_images = images.numpy()\n        numpy_labels = labels.numpy()\n        break;  \n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    label = np.argmax(label, axis=-1)\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(label, str(correct), ', shoud be ' if not correct else '',\n                                correct_label if not correct else ''), correct\n\ndef display_one_flower_eval(image, title, subplot, red=False):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=14, color='red' if red else 'black')\n    return subplot+1\n\ndef display_9_images_with_predictions(images, predictions, labels):\n    subplot=331\n    plt.figure(figsize=(13,13))\n    for i, image in enumerate(images):\n        title, correct = title_from_label_and_target(predictions[i], labels[i])\n        subplot = display_one_flower_eval(image, title, subplot, not correct)\n        if i >= 8:\n            break;\n              \n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\n\n\n# Model evaluation\ndef plot_metrics(history):\n    fig, axes = plt.subplots(2, 1, sharex='col', figsize=(20, 8))\n    axes = axes.flatten()\n    \n    axes[0].plot(history['loss'], label='Train loss')\n    axes[0].plot(history['val_loss'], label='Validation loss')\n    axes[0].legend(loc='best', fontsize=16)\n    axes[0].set_title('Loss')\n    axes[0].axvline(np.argmin(history['loss']), linestyle='dashed')\n    axes[0].axvline(np.argmin(history['val_loss']), linestyle='dashed', color='orange')\n    \n    axes[1].plot(history['accuracy'], label='Train accuracy')\n    axes[1].plot(history['val_accuracy'], label='Validation accuracy')\n    axes[1].legend(loc='best', fontsize=16)\n    axes[1].set_title('Accuracy')\n    axes[1].axvline(np.argmax(history['accuracy']), linestyle='dashed')\n    axes[1].axvline(np.argmax(history['val_accuracy']), linestyle='dashed', color='orange')\n\n    plt.xlabel('Epochs', fontsize=16)\n    sns.despine()\n    plt.show()","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training data samples (with augmentation)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"train_dataset = get_dataset(FILENAMES_COMP, ordered=True, augment=True, mixup=True)\ntrain_iter = iter(train_dataset.unbatch().batch(20))\n\ndisplay_batch_of_images(next(train_iter))\n","execution_count":41,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-f15fe9f55245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAMES_COMP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_batch_of_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-f7d03e8d8dae>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(FILENAMES, labeled, ordered, repeated, cached, augment, mixup)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#need to batch to use CutMix/mixup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUG_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_and_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#now unbatch and shuffle before re-batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1810\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4246\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmp8_jdx8mi.py\u001b[0m in \u001b[0;36mtf__cut_and_mix\u001b[0;34m(image, label, DIM)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mCUTMIX_PROB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mMIXUP_PROB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutmix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUTMIX_PROB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mimage3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMIXUP_PROB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m       \u001b[0m_attach_error_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmphx80105f.py\u001b[0m in \u001b[0;36mtf__cutmix\u001b[0;34m(image, label, PROBABILITY, DIM)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mtwo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'two'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUG_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'j'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mimage2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUG_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUG_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    471\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m       \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmphx80105f.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mtwo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mthree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1023\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1024\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1523\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0;31m# convertible-to-tensor types, such as numpy arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           elems_as_tensors.append(\n\u001b[0;32m-> 1460\u001b[0;31m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0m\u001b[1;32m   1461\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 287\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    590\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3536\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2016\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1826\u001b[0m   op_desc = pywrap_tf_session.TF_NewOperation(graph._c_graph,\n\u001b[1;32m   1827\u001b[0m                                               \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                                               compat.as_str(node_def.name))\n\u001b[0m\u001b[1;32m   1829\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_str\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compat.as_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_text\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \"\"\"Converts any string-like python input types to unicode.\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## Datasets distribution\n\n### Competition data"},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"ds_comp = get_dataset(FILENAMES_COMP)\nlabels_comp = [target.numpy() for img, target in iter(ds_comp.unbatch())]\nlabels_comp = np.argmax(labels_comp, axis=-1)\n\nfig, ax = plt.subplots(1, 1, figsize=(18, 8))\nax = sns.countplot(y=labels_comp, palette='viridis')\nax.tick_params(labelsize=16)\n\nplt.show()","execution_count":40,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-046e4f9133ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAMES_COMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-046e4f9133ad>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAMES_COMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"### 2019 competition data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds_2019 = get_dataset(FILENAMES_2019)\nlabels_2019 = [target.numpy() for img, target in iter(ds_2019.unbatch())]\nlabels_2019 = np.argmax(labels_2019, axis=-1)\n\nfig, ax = plt.subplots(1, 1, figsize=(18, 8))\nax = sns.countplot(y=labels_2019, palette='viridis')\nax.tick_params(labelsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset oversampled"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"FILENAMES_COMP_OVER = (FILENAMES_COMP + \n                       FILENAMES_2019 + \n                       (2 * FILENAMES_COMP_CBB) + \n                       (2 * FILENAMES_2019_CBB) + \n                       (2 * FILENAMES_COMP_CBSD) + \n                       (2 * FILENAMES_2019_CBSD) + \n                       (2 * FILENAMES_COMP_CGM) + \n                       (2 * FILENAMES_2019_CGM) + \n                       (2 * FILENAMES_COMP_Healthy) + \n                       (2 * FILENAMES_2019_Healthy))\n\nds_comp = get_dataset(FILENAMES_COMP_OVER)\nlabels_comp = [target.numpy() for img, target in iter(ds_comp.unbatch())]\nlabels_comp = np.argmax(labels_comp, axis=-1)\n\nfig, ax = plt.subplots(1, 1, figsize=(18, 8))\nax = sns.countplot(y=labels_comp, palette='viridis')\nax.tick_params(labelsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.151388,"end_time":"2020-10-10T21:30:00.486807","exception":false,"start_time":"2020-10-10T21:30:00.335419","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Learning rate schedule\n\nWe are going to use a `cosine learning rate schedule with a warm-up phase`, this may be a good idea since we are using a pre-trained model, the warm-up phase will be useful to avoid the pre-trained weights degradation resulting in catastrophic forgetting, during the schedule the learning rate will slowly decrease to very low values, this helps the model to land on more stable weights."},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T21:30:00.81171Z","iopub.status.busy":"2020-10-10T21:30:00.803307Z","iopub.status.idle":"2020-10-10T21:30:01.170422Z","shell.execute_reply":"2020-10-10T21:30:01.169829Z"},"papermill":{"duration":0.532334,"end_time":"2020-10-10T21:30:01.170556","exception":false,"start_time":"2020-10-10T21:30:00.638222","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"lr_start = 1e-8\nlr_min = 1e-8\nlr_max = LEARNING_RATE\nnum_cycles = 1.\nwarmup_epochs = 1\nhold_max_epochs = 0\ntotal_epochs = EPOCHS\nwarmup_steps = warmup_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\ntotal_steps = total_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\n\n@tf.function\ndef lrfn(step):\n    if step < warmup_steps:\n        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n    else:\n        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n        lr = lr_max * (0.5 * (1.0 + tf.math.cos(np.pi * ((num_cycles * progress) % 1.0))))\n        if lr_min is not None:\n            lr = tf.math.maximum(lr_min, float(lr))\n\n    return lr\n\n\n# rng = [i for i in range(total_epochs)]\nrng = [i for i in range(total_steps)]\ny = [lrfn(tf.cast(x, tf.float32)) for x in rng]\n\nsns.set(style='whitegrid')\nfig, ax = plt.subplots(figsize=(20, 6))\nplt.plot(rng, y)\n\nprint(f'{total_steps} total steps and {NUM_TRAINING_IMAGES//BATCH_SIZE} steps per epoch')\nprint(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')","execution_count":42,"outputs":[{"output_type":"stream","text":"7510 total steps and 751 steps per epoch\nLearning rate schedule: 1e-08 to 8e-05 to 1e-08\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x432 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"papermill":{"duration":0.149079,"end_time":"2020-10-10T21:26:06.196269","exception":false,"start_time":"2020-10-10T21:26:06.04719","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Model"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-10T21:26:06.501284Z","iopub.status.busy":"2020-10-10T21:26:06.500306Z","iopub.status.idle":"2020-10-10T21:26:06.503182Z","shell.execute_reply":"2020-10-10T21:26:06.502614Z"},"papermill":{"duration":0.159056,"end_time":"2020-10-10T21:26:06.50331","exception":false,"start_time":"2020-10-10T21:26:06.344254","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def model_fn(input_shape, N_CLASSES):\n    inputs = L.Input(shape=input_shape, name='input_image')\n    base_model = efn.EfficientNetB4(input_tensor=inputs, \n                                    include_top=False, \n                                    weights='noisy-student', \n                                    pooling='avg')\n    base_model.trainable = False\n\n    x = L.Dropout(.5)(base_model.output)\n    output = L.Dense(N_CLASSES, activation='softmax', name='output')(x)\n    model = Model(inputs=inputs, outputs=output)\n\n    return model","execution_count":43,"outputs":[]},{"metadata":{"papermill":{"duration":0.152125,"end_time":"2020-10-10T21:30:01.481735","exception":false,"start_time":"2020-10-10T21:30:01.32961","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Training"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\noof_pred = []; oof_labels = []; history_list = []\n\nfor fold,(idxT, idxV) in enumerate(skf.split(np.arange(50))):\n    if fold >= FOLDS_USED:\n        break\n    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    K.clear_session()\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {idxT} VALID: {idxV}')\n\n    # Create train and validation sets\n    FILENAMES_COMP = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_2019 = tf.io.gfile.glob([GCS_PATH_EXT + '/Id_train%.2i*.tfrec' % x for x in idxT])\n\n    FILENAMES_COMP_CBB = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_COMP_CBSD = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_COMP_CGM = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_COMP_Healthy = tf.io.gfile.glob([GCS_PATH_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n    \n    FILENAMES_2019_CBB = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_2019_CBSD = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_2019_CGM = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n    FILENAMES_2019_Healthy = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n\n    TRAIN_FILENAMES = (FILENAMES_COMP + \n                       FILENAMES_2019 + \n                       (2 * FILENAMES_COMP_CBB) + \n                       (2 * FILENAMES_2019_CBB) + \n                       (2 * FILENAMES_COMP_CBSD) + \n                       (2 * FILENAMES_2019_CBSD) + \n                       (2 * FILENAMES_COMP_CGM) + \n                       (2 * FILENAMES_2019_CGM) + \n                       (2 * FILENAMES_COMP_Healthy) + \n                       (2 * FILENAMES_2019_Healthy))\n    \n    VALID_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxV])\n    np.random.shuffle(TRAIN_FILENAMES)\n    \n    ct_train = count_data_items(TRAIN_FILENAMES)\n    ct_valid = count_data_items(VALID_FILENAMES)\n    \n    step_size = (ct_train // BATCH_SIZE)\n    valid_step_size = (ct_valid // BATCH_SIZE)\n    total_steps=(total_epochs * step_size)\n    warmup_steps=(warmup_epochs * step_size)\n    \n    \n    # Build TF datasets\n    train_ds = strategy.experimental_distribute_dataset(get_dataset(TRAIN_FILENAMES, repeated=True, augment=True, mixup=True))\n    valid_ds = strategy.experimental_distribute_dataset(get_dataset(VALID_FILENAMES, ordered=True, repeated=True, cached=True))\n    train_data_iter = iter(train_ds)\n    valid_data_iter = iter(valid_ds)\n    \n    \n    # Step functions\n    @tf.function\n    def train_step(data_iter):\n        def train_step_fn(x, y):\n            with tf.GradientTape() as tape:\n                probabilities = model(x, training=True)\n                loss = loss_fn(y, probabilities, label_smoothing=.3)\n            gradients = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n            # update metrics\n            train_accuracy.update_state(y, probabilities)\n            train_loss.update_state(loss)\n        for _ in tf.range(step_size):\n            strategy.experimental_run(train_step_fn, next(data_iter))\n\n    @tf.function\n    def valid_step(data_iter):\n        def valid_step_fn(x, y):\n            probabilities = model(x, training=False)\n            loss = loss_fn(y, probabilities)\n            # update metrics\n            valid_accuracy.update_state(y, probabilities)\n            valid_loss.update_state(loss)\n        for _ in tf.range(valid_step_size):\n            strategy.experimental_run(valid_step_fn, next(data_iter))\n    \n    \n    # Model\n    model_path = f'model_{fold}.h5'\n    with strategy.scope():\n        model = model_fn((None, None, CHANNELS), N_CLASSES)\n        unfreeze_model(model) # unfreeze all layers except \"batch normalization\"\n        \n        optimizer = optimizers.Adam(learning_rate=lambda: lrfn(tf.cast(optimizer.iterations, tf.float32)))\n        loss_fn = losses.categorical_crossentropy\n\n        train_accuracy = metrics.CategoricalAccuracy()\n        valid_accuracy = metrics.CategoricalAccuracy()\n        train_loss = metrics.Sum()\n        valid_loss = metrics.Sum()\n    \n    \n    # Setup training loop\n    step = 0\n    epoch_steps = 0\n    patience_cnt = 0\n    best_val = 0\n    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n\n    ### Train model\n    for epoch in range(EPOCHS):\n        epoch_start_time = time.time()\n\n        # Run training step\n        train_step(train_data_iter)\n        epoch_steps += step_size\n        step += step_size\n            \n\n        # Validation run at the end of each epoch\n        if (step // step_size) > epoch:\n            # Validation run\n            valid_epoch_steps = 0\n            valid_step(valid_data_iter)\n            valid_epoch_steps += valid_step_size\n\n            # Compute metrics\n            history['accuracy'].append(train_accuracy.result().numpy())\n            history['loss'].append(train_loss.result().numpy() / (BATCH_SIZE * epoch_steps))\n            history['val_accuracy'].append(valid_accuracy.result().numpy())\n            history['val_loss'].append(valid_loss.result().numpy() / (BATCH_SIZE * valid_epoch_steps))\n\n            # Report metrics\n            epoch_time = time.time() - epoch_start_time\n            print(f'\\nEPOCH {epoch+1}/{EPOCHS}')\n            print(f'time: {epoch_time:0.1f}s',\n                  f\"loss: {history['loss'][-1]:0.4f}\",\n                  f\"accuracy: {history['accuracy'][-1]:0.4f}\",\n                  f\"val_loss: {history['val_loss'][-1]:0.4f}\",\n                  f\"val_accuracy: {history['val_accuracy'][-1]:0.4f}\",\n                  f'lr: {lrfn(tf.cast(optimizer.iterations, tf.int32).numpy()):0.4g}')\n\n            # Early stopping monitor\n            if history['val_accuracy'][-1] >= best_val:\n                best_val = history['val_accuracy'][-1]\n                model.save_weights(model_path)\n                print(f'Saved model weights at \"{model_path}\"')\n                patience_cnt = 1\n            else:\n                patience_cnt += 1\n            if patience_cnt > ES_PATIENCE:\n                print(f'Epoch {epoch:05d}: early stopping')\n                break\n\n                \n            # Set up next epoch\n            epoch = step // step_size\n            epoch_steps = 0\n            train_accuracy.reset_states()\n            train_loss.reset_states()\n            valid_accuracy.reset_states()\n            valid_loss.reset_states()\n    \n    \n    ### RESULTS\n    print(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_accuracy']):.3f}\")\n    \n    history_list.append(history)\n    # Load best model weights\n    model.load_weights(model_path)\n\n    # OOF predictions\n    ds_valid = get_dataset(VALID_FILENAMES, ordered=True)\n    oof_labels.append([target.numpy() for img, target in iter(ds_valid.unbatch())])\n    x_oof = ds_valid.map(lambda image, target: image)\n    oof_pred.append(np.argmax(model.predict(x_oof), axis=-1))","execution_count":45,"outputs":[{"output_type":"stream","text":"\nFOLD: 1\nTRAIN: [ 0  1  3 ... 47 48 49] VALID: [ 2  4 10 11 22 27 28 31 38 41]\n<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'val_ds' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-85772eb2d1b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mvalid_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mvalid_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'val_ds' is not defined"]}]},{"metadata":{"papermill":{"duration":0.157699,"end_time":"2020-10-10T22:09:56.87745","exception":false,"start_time":"2020-10-10T22:09:56.719751","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Model loss graph"},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T22:09:57.231883Z","iopub.status.busy":"2020-10-10T22:09:57.231124Z","iopub.status.idle":"2020-10-10T22:09:57.902666Z","shell.execute_reply":"2020-10-10T22:09:57.901809Z"},"papermill":{"duration":0.861991,"end_time":"2020-10-10T22:09:57.902823","exception":false,"start_time":"2020-10-10T22:09:57.040832","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for fold, history in enumerate(history_list):\n    print(f'\\nFOLD: {fold+1}')\n    plot_metrics(history)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.180457,"end_time":"2020-10-10T22:09:58.291265","exception":false,"start_time":"2020-10-10T22:09:58.110808","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Model evaluation\n\nNow we can evaluate the performance of the model, first, we can evaluate the usual metrics like, `accuracy`, `precision`, `recall`, and `f1-score`, `scikit-learn` provides the perfect function for this `classification_report`.\n\nWe are evaluating the model on the `OOF` predictions, it stands for `Out Of Fold`, since we are training using `K-Fold` our model will see all the data, and the correct way to evaluate each fold is by looking at the predictions that are not from that fold.\n\n## OOF metrics"},{"metadata":{},"cell_type":"markdown","source":"#### I am still having some problems to get the real model `OOF` scores while using `TPU Pods`, so the results here and the confusion matrix are just placeholders."},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T22:10:44.510949Z","iopub.status.busy":"2020-10-10T22:10:44.510261Z","iopub.status.idle":"2020-10-10T22:10:49.740311Z","shell.execute_reply":"2020-10-10T22:10:49.739452Z"},"papermill":{"duration":5.399145,"end_time":"2020-10-10T22:10:49.740438","exception":false,"start_time":"2020-10-10T22:10:44.341293","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"y_true = np.concatenate(oof_labels)\ny_true = np.argmax(y_true, axis=-1)\ny_pred = np.concatenate(oof_pred)\n\nprint(classification_report(y_true, y_pred, target_names=CLASSES))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.165203,"end_time":"2020-10-10T22:10:50.079293","exception":false,"start_time":"2020-10-10T22:10:49.91409","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Confusion matrix\n\nLet's also take a look at the confusion matrix, this will give us an idea about what classes the model is mixing or having a hard time."},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T22:10:50.445555Z","iopub.status.busy":"2020-10-10T22:10:50.444837Z","iopub.status.idle":"2020-10-10T22:10:54.125002Z","shell.execute_reply":"2020-10-10T22:10:54.12552Z"},"papermill":{"duration":3.872244,"end_time":"2020-10-10T22:10:54.125651","exception":false,"start_time":"2020-10-10T22:10:50.253407","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 12))\ncfn_matrix = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))\ncfn_matrix = (cfn_matrix.T / cfn_matrix.sum(axis=1)).T\ndf_cm = pd.DataFrame(cfn_matrix, index=CLASSES, columns=CLASSES)\nax = sns.heatmap(df_cm, cmap='Blues', annot=True, fmt='.2f', linewidths=.5).set_title('Train', fontsize=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.168779,"end_time":"2020-10-10T22:10:58.678136","exception":false,"start_time":"2020-10-10T22:10:58.509357","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Visualize predictions\n\nFinally, it is a good practice to always inspect some of the model's prediction by looking at the data, this can give an idea if the model is getting some predictions wrong because the data is really hard, of if it is because the model is actually bad.\n\n\n### Class map\n```\n0: Cassava Bacterial Blight (CBB)\n1: Cassava Brown Streak Disease (CBSD)\n2: Cassava Green Mottle (CGM)\n3: Cassava Mosaic Disease (CMD)\n4: Healthy\n```\n\n\n## Train set"},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-10T22:10:59.029492Z","iopub.status.busy":"2020-10-10T22:10:59.027464Z","iopub.status.idle":"2020-10-10T22:11:21.88443Z","shell.execute_reply":"2020-10-10T22:11:21.885182Z"},"papermill":{"duration":23.038156,"end_time":"2020-10-10T22:11:21.885383","exception":false,"start_time":"2020-10-10T22:10:58.847227","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_dataset = get_dataset(TRAINING_FILENAMES, ordered=True)\nx_samp, y_samp = dataset_to_numpy_util(train_dataset, 18)\ny_samp = np.argmax(y_samp, axis=-1)\n\nx_samp_1, y_samp_1 = x_samp[:9,:,:,:], y_samp[:9]\nsamp_preds_1 = model.predict(x_samp_1, batch_size=9)\ndisplay_9_images_with_predictions(x_samp_1, samp_preds_1, y_samp_1)\n\nx_samp_2, y_samp_2 = x_samp[9:,:,:,:], y_samp[9:]\nsamp_preds_2 = model.predict(x_samp_2, batch_size=9)\ndisplay_9_images_with_predictions(x_samp_2, samp_preds_2, y_samp_2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}