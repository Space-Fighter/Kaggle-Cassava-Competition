{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Imports\nNothing interesting here. ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ðŸ’¤ ok stop sleeping there is also the rest of the notebook to walkthroughðŸ˜œ"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Keras Tuner Stuff\nfrom kerastuner.tuners.hyperband import Hyperband\nfrom kerastuner.engine.hyperparameters import HyperParameters\n# Tensorflow Stuff\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dense, Flatten\nimport tensorflow.keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n# Data Splitting Stuff\nfrom sklearn.model_selection import train_test_split\n# from tensorflow.keras.layers import Batchnorm2D, Conv2D, MaxPooling2D, Dense, Flatten, Activation\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Image Handler Stuff\nimport matplotlib.pyplot as plt\nimport cv2\n# Dataframe Handler Stuff\nimport pandas as pd\n# Array Handler Stuff\nimport numpy as np\n# Other stuff\nimport os\nfrom tqdm import tqdm as tqdm\nimport os\nfrom functools import partial\nimport math\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bunccha good ideas - \n\nhttps://www.kaggle.com/tuckerarrants/cassava-tensorflow-starter-training"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 2. TPU SETUP\n\nHere are some excellent notebooks to refer - \n\nhttps://www.kaggle.com/jessemostipak/getting-started-tpus-cassava-leaf-disease/data\n\nhttps://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-training-with-tpu-v2-pods/notebook\n\nhttps://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-tpu-tensorflow-training\n\nOther good notebooks but on gpu - \n\nhttps://www.kaggle.com/frlemarchand/efficientnet-aug-tf-keras-for-cassava-diseases"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nreplicas = strategy.num_replicas_in_sync\nprint('Number of replicas:', strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some setup variables\n\nThe GCS Path thingy stuff explaination-\n\n**TPUs read data directly from Google Cloud Storage (GCS), so we actually need to copy our dataset to a GCS 'bucket' that is near or 'co-located' with the TPU. The below chunk of code accomplishes this using the handy KaggleDatasets:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * replicas\nIMAGE_SIZE = [512, 512]\nHEIGHT = 512\nWIDTH = 512\nCHANNELS = 3\nCLASSES = ['0', '1', '2', '3', '4']\nfrom kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_PATH)\nprint(BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Loading in our data\n\nSome excellent notebooks on tfrecords\n\nhttps://www.kaggle.com/ryanholbrook/tfrecords-basics\n\nWe are gonna load our data via tfrecords. Now tfrecords as tensorflow suggests is best to feed data to a TPU. So we are gonna go with that.ðŸ™‚"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 1. Decode Image Function and Stuff\nThe following is a decoding function what it does is takes in an image in jpg form and converts it into an array. Unlike the numpy stuff you know.\nThen the cast thingy converts the pixel thingies into floats so we can divide by a float that is 255.0 to normalize the stuff and all. You know normalization helps in training lolðŸ˜‚."},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well if you do not want to spend alot of time in understanding how tfrecords work just pick up other people's code use that to load data and then train and move forward.ðŸ˜œ"},{"metadata":{},"cell_type":"markdown","source":"### 2. Read tfrecord\n\nBasically reads our tfrecord file and handles both for labelled and non labelled images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    return image, idnum","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Load Dataset from filenames Function\nThis just loads in data and thats all we need to know and this only handles for labelled images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Make a list of train_filenames and val_filenames\n\nThe ```tf.io.gfile.glob``` is basically reading GCS path that is the GCS path to our Cassava competition data in which we have the train tfrecords. And then using the ```tf.io.gfile.glob``` we are getting a list of paths to our GCS path to the tfrecord where our TPU is located and then on top of that we use sklearns ```train_test_split``` to get buncha filenames for training and validation which we are later gonna load."},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n    tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec'),\n    test_size=0.15, random_state=5\n)\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. The Augmentation Functions - \n\nThe following amazing function has been taken from this notebook - \nhttps://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-training-with-tpu-v2-pods\n\nBasically the vars at the starting like rotation, spatial p_pixel1 and so on are equating to a random number between 0 and 1.0 so what we get is a random number then the below ifs and elses are like if we get a number in the if's range to the var corresponding to its augmentation name then great we apply that augmentation. This brings in randomicity in the augmentations applied.\nðŸ˜€"},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):\n    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    # Shear\n    if p_shear > .2:\n        if p_shear > .6:\n            image = transform_shear(image, HEIGHT, shear=20.)\n        else:\n            image = transform_shear(image, HEIGHT, shear=-20.)\n            \n    # Rotation\n    if p_rotation > .2:\n        if p_rotation > .6:\n            image = transform_rotation(image, HEIGHT, rotation=45.)\n        else:\n            image = transform_rotation(image, HEIGHT, rotation=-45.)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270Âº\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180Âº\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90Âº\n        \n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    # Crops\n    if p_crop > .6:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.5)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.6)\n        elif p_crop > .7:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.8)\n    elif p_crop > .3:\n        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n            \n    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n\n    if p_cutout > .5:\n        image = data_augment_cutout(image)\n        \n    return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Helper functions for the augmentation function -\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\ndef transform_rotation(image, height, rotation):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated\n    DIM = height\n    XDIM = DIM%2 #fix for size 331\n    \n    rotation = rotation * tf.random.uniform([1],dtype='float32')\n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3])\n\ndef transform_shear(image, height, shear):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly sheared\n    DIM = height\n    XDIM = DIM%2 #fix for size 331\n    \n    shear = shear * tf.random.uniform([1],dtype='float32')\n    shear = math.pi * shear / 180.\n        \n    # SHEAR MATRIX\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3])\n\n# CutOut\ndef data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    if p_cutout > .85: # 10~15 cut outs\n        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    elif p_cutout > .6: # 5~10 cut outs\n        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    elif p_cutout > .25: # 2~5 cut outs\n        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n    else: # 1 cut out\n        image = random_cutout(image, HEIGHT, WIDTH, \n                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n\n    return image\n\ndef random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n    assert height > min_mask_size[0]\n    assert width > min_mask_size[1]\n    assert height > max_mask_size[0]\n    assert width > max_mask_size[1]\n\n    for i in range(k):\n      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n\n      pad_h = height - mask_height\n      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n      pad_bottom = pad_h - pad_top\n\n      pad_w = width - mask_width\n      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n      pad_right = pad_w - pad_left\n\n      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n\n      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Load Data Functions to now bring in our train, test data etc into variables and stuff"},{"metadata":{},"cell_type":"markdown","source":"The following loads the training data. Remember the files we split recently into train files and others stuff files. So it will give the ```TRAINING_FILENAMES``` to the load_dataset function we created earlier with ```labelled = True``` as we know our training filenames are obviously gonna have labels.\nNext ```dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE) ``` is applying our data_augment function to our dataset which we created earlier.\nThen  we shuffle. Then we are breaking our dataset into batches we defined then we are finally returning our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  \n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This loads our validation data breaks it into batches and returns it to us."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Explore the data"},{"metadata":{},"cell_type":"markdown","source":"The following cells are just to count the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n\nprint('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at a few images\nThe following are not at all an important piece of code."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_plant(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n\ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_plant(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load our training dataset for visualisation\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = iter(training_dataset)\n# run this cell again for another randomized set of training images\ndisplay_batch_of_images(next(train_batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load our validation dataset for EDA\nval_dataset = get_validation_dataset()\nval_dataset = val_dataset.unbatch().batch(20)\ntest_batch = iter(val_dataset)\ndisplay_batch_of_images(next(test_batch))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. The Training\n### 1. Callbacks - \n\nFirst of we are gonna make a learning rate scheduler callback. Here is what it is gonna do - \n\n1. Initial lr is 0.1\n2. Will store loss in a dict\n3. On every 10 batch end if loss did not reduce more than by 0.1 we make lr 10 times the present lr. Then after 3 batches check if lr improved by more than 0.1 or not. If it did we multiply present lr with a decay of 0.01. If it did not we bring back the lr which was there by multiplying present lr by 0.1\n3. If after every 10 batch end if loss does improve we decay the present lr by 0.5\n\nWe would have liked that but that's much out of my mind how to make that code.\nSo we are going to go simple like this - "},{"metadata":{},"cell_type":"markdown","source":"Next a model checkpoint. But we won't be needing one as the kerastuner package saves everything for us. Next tensorboard and all other good stuff"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorboard = TensorBoard(log_dir='logs_v0.2/')\nreducelr = ReduceLROnPlateau(patience=1)\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience = 3, mode = 'min')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The model architecture - "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom kerastuner.applications import HyperResNet\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation, Dropout, BatchNormalization\ndef build_model(hp):  # random search passes this hyperparameter() object \n        model = keras.models.Sequential()\n        # Input Layer\n        if hp.Boolean(name='Conv_Input_kernel_size'):# Which kernel size to use\n            k_size = (3, 3)\n        else:\n            k_size = (5, 5)\n        model.add(Conv2D(filters=hp.Int('input_units',\n                                    min_value=32,\n                                    max_value=512,\n                                    step=32), \n                         kernel_size=k_size, \n                         padding='same', \n                         activation = 'relu',\n                         input_shape=(HEIGHT, WIDTH, CHANNELS)))\n        if hp.Boolean(name='Use_pooling_or_not'):# add pooling or not\n            if hp.Boolean(name='Pool filter size'):# What kernel size of pooling to use\n                model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n            else:\n                model.add(MaxPooling2D(pool_size=(5, 5), padding='same'))\n            \n        if hp.Boolean(name='Batch Norm'):\n            model.add(BatchNormalization())\n\n        for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.\n            if hp.Boolean(name=f'conv_k_size{i}_units'):\n                k_size = (3, 3)\n            else:\n                k_size = (5, 5)\n            model.add(Conv2D(filters=hp.Int(f'conv_{i}_units',\n                                        min_value=32,\n                                        max_value=512,\n                                        step=32), \n                             kernel_size=k_size, \n                             padding='same', \n                             activation = 'relu'\n                             ))\n            if hp.Boolean(name='Use_pooling_or_not'):\n                if hp.Boolean(name=f'pool{i}_units'):\n                    model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n                else:\n                    model.add(MaxPooling2D(pool_size=(5, 5), padding='same'))\n            if hp.Boolean(name=f'Norm{i}_units'):\n                model.add(BatchNormalization())\n        model.add(Flatten()) \n        model.add(Dense(5, activation='softmax'))\n        lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n                                                initial_learning_rate=hp.Float('Initial_LR', max_value=0.01, min_value=0.00001),\n                                                decay_steps=10000, \n                                                decay_rate=0.9)\n        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n        \n        model.compile(optimizer=optimizer,\n                      loss=\"sparse_categorical_crossentropy\",\n                      metrics=[\"accuracy\"])\n\n        return model    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    tuner = Hyperband(build_model, \n                      objective='val_loss', \n                      max_epochs=5, \n                      executions_per_trial=5,# how many trials per variation? (same model could perform differently), \n                      directory='models', \n                      project_name = 'v0.2',\n                      )\n    history = tuner.search(train_dataset,\n             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n             epochs=10,\n             steps_per_epoch=STEPS_PER_EPOCH,\n             validation_steps=VALID_STEPS,\n             batch_size=BATCH_SIZE,\n             callbacks=[tensorboard, reducelr, earlystop],  # if you have callbacks like tensorboard, they go here.\n             validation_data=valid_dataset)\n\n    tuner.search_space_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    hypermodel = HyperResNet(input_shape=(HEIGHT, WIDTH, 3), classes=5)\n    tuner = Hyperband(hypermodel, \n                  objective='val_loss', \n                  max_epochs=40, \n                  #executions_per_trial=5,# how many trials per variation? (same model could perform differently), \n                  directory='models', \n                  project_name = 'v0.2',\n                  )\n    history = tuner.search(train_dataset,\n             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n             epochs=10,\n             steps_per_epoch=STEPS_PER_EPOCH,\n             validation_steps=VALID_STEPS,\n             batch_size=BATCH_SIZE,\n             callbacks=[tensorboard, reducelr, earlystop],  # if you have callbacks like tensorboard, they go here.\n             validation_data=valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}